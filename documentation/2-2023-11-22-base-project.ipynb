{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Base Project (22.11.2023)\n",
    "\n",
    "## What happened?\n",
    "In this project phase, we initially dealt with the resources provided to us, the Vue base project and examples of how to use Python and OpenCV. In order to be able to start the first tests, we agreed on a standardized IDE usage and decided on the IDE PyCharm. Our first self-imposed task was to test the use of basic filters such as Blur, Black and White and Invert on various images. In the meantime, we also worked intensively with the detailed [documentation of OpenCV](https://docs.opencv.org/4.8.0/). Our aim was to develop a deeper understanding of the functionalities and their parameters and to establish possible connections to the content of the lectures. Once the filters were in place, we started with the implementation of the base project for the front- and backend. We decided against using the provided Vue base project and therefore had to start from scratch.\n",
    "\n",
    "## Filters\n",
    "We have added three different basic filters to apply to the images: Blur, Black and White and Invert. Since this is a prototype we just wanted to showcase what would be possible with our application. Therefore we did not implement any elaborate filters. Even though the filters are not an essential part of our project, using the filters has helped us to familiarize ourselves with OpenCV and Python.\n",
    "\n",
    "### Blur\n",
    "For the blur filter, we used the method [cv2.blur](https://docs.opencv.org/4.8.0/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37) provided by OpenCV. We only had to find a suitable kernel size.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34744ea329cdc70e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "filename = \"./assets/a6a53142-eabf-469a-b10d-6c87e6776120.jpg\"\n",
    "image = cv2.imread(filename)\n",
    "kernel_size = (10, 10)\n",
    "image_blur = cv2.blur(image, kernel_size)\n",
    "\n",
    "# The code that follows is purely for plotting purposes.\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Image\")\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Blur\")\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(cv2.cvtColor(image_blur, cv2.COLOR_BGR2RGB))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41e2bfcf751045b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Black and White\n",
    "For the Black and White filter, we used the [cv2.cvtColor](https://docs.opencv.org/4.8.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab) method and [cv2.threshold](https://docs.opencv.org/4.8.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57) method provided by OpenCV.\n",
    "\n",
    "With [cv2.cvtColor](https://docs.opencv.org/4.8.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab), the effect has already been achieved in the broadest sense, as all colors have been converted to corresponding gray values. To improve the effect, we subsequently applied [cv2.threshold](https://docs.opencv.org/4.8.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57). Here we opted for the [cv2.THRESH_TOZERO](https://docs.opencv.org/4.8.0/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576a0e50a338a4b711a8c48f06a6b105dd98) procedure. The procedure goes through each pixel value and checks whether it is below the set threshold. If this is the case, the checked pixel value is colored black. This allows significantly higher contrast Black and White images to be created than with conversion alone.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cba39bce2823f23"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "filename = \"./assets/a6a53142-eabf-469a-b10d-6c87e6776120.jpg\"\n",
    "image = cv2.imread(filename)\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, image_black_and_white = cv2.threshold(image_gray, 25, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "# The code that follows is purely for plotting purposes.\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Image\")\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Gray\")\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(cv2.cvtColor(image_gray, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Black and White\")\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(cv2.cvtColor(image_black_and_white, cv2.COLOR_BGR2RGB))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "856fcdc10792a1cd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invert\n",
    "For the inversion filter, we used the [cv2.bitwise_not](https://docs.opencv.org/4.8.0/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f) method provided by OpenCV.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7fd45b7bc1384f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "filename = \"./assets/a6a53142-eabf-469a-b10d-6c87e6776120.jpg\"\n",
    "image = cv2.imread(filename)\n",
    "image_invert = cv2.bitwise_not(image)\n",
    "\n",
    "# The code that follows is purely for plotting purposes.\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Invert\")\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(image_invert, cv2.COLOR_BGR2RGB))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71aa5253b1ba4aa7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base project\n",
    "The project was divided into the backend, frontend and documentation areas. This ensured that the areas and their content were clearly separated from each other. After some research, we opted for the [Flask web framework](https://flask.palletsprojects.com/en/3.0.x/) for the development of the backend and for the development of the frontend we chose [React](https://react.dev), as it allows a prototype to be implemented very quickly and easily. We then started developing our prototype.\n",
    "\n",
    "### Challenges\n",
    "At this point, we kept the images in the frontend and sent them to the backend for further processing, e.g. to apply the filters. However, as the memory requirements increased with more images in the frontend, this led to increased performance problems in the frontend.\n",
    "\n",
    "## Prototype\n",
    "<p>This is the status of the prototype as of 22.11.2023. In the first step, we implemented the areas (help, camera, action log, image carousel and the filter bar). Only the image carousel and the filters were functional. The filters could only be applied or resetted manually.</p>\n",
    "<br/>\n",
    "<img src=\"./images/2023-11-22-prototype.jpeg\" alt=\"GUI as of the 22nd November 2023\" width=\"750\"/>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c3259b7fba26aca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
